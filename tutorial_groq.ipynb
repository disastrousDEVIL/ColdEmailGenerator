{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Run the following commands one at a time , to install the necessary"
      ],
      "metadata": {
        "id": "uDWKQwpdfJvy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#pip install langchain\n",
        "#pip install langchain-community\n",
        "#pip install langchain-groq"
      ],
      "metadata": {
        "id": "vIkHFy0bYE1S"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "OMXEnx8bSNEZ"
      },
      "outputs": [],
      "source": [
        "from langchain_groq import ChatGroq\n",
        "import os\n",
        "from secret_key import GROQ_API_KEY"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"GROQ_API_KEY\"] = GROQ_API_KEY\n",
        "llm = ChatGroq(\n",
        "    temperature=0.4,  #temperature is measure of how creative and away from facts the response of LLM should be (Range:[0,1]) , \"0\" being the least creative\n",
        "    groq_api_key=os.getenv(\"GROQ_API_KEY\"),\n",
        "    model_name=\"llama3-8b-8192\"\n",
        ")"
      ],
      "metadata": {
        "id": "i04nTsgATuWR"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response=llm.invoke(\"how much powerful META's llama3.1 is over openai GPT, keep it precise and factual\")\n",
        "response.content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "SR56yjxKVg6l",
        "outputId": "6ef06c7a-04c4-4d14-9941-2c732f245a5a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'META\\'s LLaMA 3.1 and OpenAI\\'s GPT are both large language models, but they have different architectures, training objectives, and capabilities. It\\'s challenging to make a direct comparison between the two, as they are designed for different tasks and have different strengths. However, I can provide some information on their performance on various benchmarks and tasks.\\n\\n**LLaMA 3.1:**\\n\\n* Training data: 45 billion parameters, trained on a dataset of 45 billion parameters, which includes a mix of text from the internet, books, and other sources.\\n* Architecture: Transformer-based model with a 32-layer encoder and a 16-layer decoder.\\n* Training objective: Masked language modeling (MLM) and next sentence prediction (NSP).\\n* Performance:\\n\\t+ GLUE benchmark: 84.1% accuracy (source: [1])\\n\\t+ SuperGLUE benchmark: 72.1% accuracy (source: [1])\\n\\t+ Long-range Arena (LRA) benchmark: 24.4% accuracy (source: [2])\\n\\n**OpenAI GPT:**\\n\\n* Training data: 1.5 billion parameters, trained on a dataset of 45 billion parameters, which includes a mix of text from the internet and books.\\n* Architecture: Transformer-based model with a 12-layer encoder and a 12-layer decoder.\\n* Training objective: Masked language modeling (MLM).\\n* Performance:\\n\\t+ GLUE benchmark: 81.5% accuracy (source: [3])\\n\\t+ SuperGLUE benchmark: 64.6% accuracy (source: [3])\\n\\t+ Long-range Arena (LRA) benchmark: 20.4% accuracy (source: [2])\\n\\n**Comparison:**\\n\\n* LLaMA 3.1 has a significantly larger model size (45 billion parameters) compared to OpenAI GPT (1.5 billion parameters).\\n* LLaMA 3.1 has better performance on the GLUE and SuperGLUE benchmarks, with 2.6% and 7.5% improvements, respectively.\\n* LLaMA 3.1 has better performance on the Long-range Arena (LRA) benchmark, with a 4% improvement.\\n\\n**Conclusion:**\\n\\nWhile both models have impressive performance, LLaMA 3.1 appears to be more powerful than OpenAI GPT in terms of its larger model size and better performance on various benchmarks. However, it\\'s essential to note that the training objectives, architectures, and datasets used for the two models are different, which makes a direct comparison challenging.\\n\\nReferences:\\n\\n[1] \"LLaMA: Open and Efficient Foundation Language Models\" by the Meta AI Research Team (2022)\\n\\n[2] \"Long-range Arena: A Benchmark for Long-range Language Understanding\" by the Google AI Research Team (2022)\\n\\n[3] \"Language Models are Few-shot Learners\" by the OpenAI Research Team (2019)'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    }
  ]
}